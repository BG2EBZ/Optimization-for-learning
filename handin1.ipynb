{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BG2EBZ/Optimization-for-learning/blob/main/handin1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkrryBlqv1zq"
      },
      "source": [
        "### Fill in group number and member names:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyUgmKUvv1zq"
      },
      "outputs": [],
      "source": [
        "GROUP = \"\"\n",
        "NAME1 = \"\"\n",
        "NAME2 = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2AKrGDXv1zr"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "# Optimization for learning - FRTN50\n",
        "\n",
        "## Assignment 1\n",
        "\n",
        "The goal of this assignment is to become familiar with some of the steps involved in solving an optimization problem. In this assignment, you will form Fenchel dual problems, find gradients and/or proximal operators, and implement the proximal gradient method.\n",
        "\n",
        "__Problem__ The problem we will solve is the following constrained problem\n",
        "\n",
        "\\begin{align}\\label{eq:the_problem}\\tag{1}\n",
        "\t\\underset{x \\in S}{\\text{minimize}}\\; \\tfrac{1}{2}x^T Q x + q^Tx\n",
        "\\end{align}\n",
        "\n",
        "where $Q\\in\\mathbb{S}_{++}^{n}$, $q\\in\\mathbb{R}^{n}$ and $S\\subseteq\\mathbb{R}^{n}$ is a set defined by the points $a,b\\in\\mathbb{R}^{n}$, $a\\leq b$, such that\n",
        "\n",
        "\\begin{align*}\n",
        "\tS = \\{x \\in \\mathbb{R}^{n}: a \\leq x \\leq b \\}.\n",
        "\\end{align*}\n",
        "\n",
        "I.e., we are going to minimize a quadratic function over an $n$-dimensional box. Recall that, the vector inequality $a\\leq b$ means that\n",
        "\n",
        "\\begin{align*}\n",
        "\ta_{i} \\leq b_{i}\n",
        "\\end{align*}\n",
        "\n",
        "for each $i=1,\\ldots,n$. Define the function $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$ such that\n",
        "\n",
        "\\begin{align*}\n",
        "\tf(x) = \\tfrac{1}{2}x^T Q x + q^Tx\n",
        "\\end{align*}\n",
        "\n",
        "for each $x\\in\\mathbb{R}^{n}$ and let $\\iota_{S}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}\\cup\\{\\infty\\}$ denote the indicator function of the set $S$, i.e.,\n",
        "\n",
        "\\begin{align*}\n",
        "\t\\iota_{S}(x) =\n",
        "\t\\begin{cases}\n",
        "\t\t0 \t\t& \\text{if }x\\in S, \\\\\n",
        "\t\t\\infty \t& \\text{if }x\\in \\mathbb{R}^n \\setminus S.\n",
        "\t\\end{cases}\n",
        "\\end{align*}\n",
        "\n",
        "Problem \\eqref{eq:the_problem} can then be written as\n",
        "\n",
        "\\begin{align}\\label{eq:the_problem_mod}\\tag{2}\n",
        "\t\\underset{x \\in \\mathbb{R}^{n}}{\\text{minimize}}\\; f(x) + \\iota_{S}(x).\n",
        "\\end{align}\n",
        "\n",
        "__Solution method__ To solve optimization problem \\eqref{eq:the_problem_mod}, we will use the _proximal gradient method_. It solves problems of the form\n",
        "\n",
        "\\begin{align}\\label{eq:pgprob}\\tag{3}\n",
        "\t\\underset{x \\in \\mathbb{R}^{n}}{\\text{minimize}}\\; f(x) + g(x)\n",
        "\\end{align}\n",
        "\n",
        "where $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$ is differentiable and $g:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}\\cup\\{\\infty\\}$ is proximable, i.e., $\\prox_{\\gamma g}$ can be cheaply computed. The proximal gradient method (with constant step-size) is given by:\n",
        "\n",
        "- Pick some arbitrary initial guess $x^0\\in\\R^{n}$ and step-size $\\gamma>0$.\n",
        "- For $k=0,1,2\\ldots$, let\n",
        "\\begin{align}\\label{eq:pg}\\tag{4}\n",
        "\t\t\t\tx^{k+1} = \\prox_{\\gamma g}\\left(x^k - \\gamma \\nabla f(x^k)\\right).\n",
        "\\end{align}\n",
        "- Stop when $x^k$ is deemed to have converged.\n",
        "\n",
        "In this assignment, we simply run the proximal gradient method a large fixed number of iterations and plot the norm of the fixed-point residual $\\norm{x^{k+1} - x^k}_{2}$ (also known as the step-length), of each step to make sure it converges to zero. Since the experiments are run on a computer, zero means smaller than machine precision, which usually is around $10^{-15}$.\n",
        "\n",
        "The step-size parameter $\\gamma$ in the \\eqref{eq:pg} will affect the convergence. It should be tuned to the problem or chosen based on properties of $f$ and $g$. In particular, suppose that $f$ and $g$ are proper, closed and convex.\n",
        "If $f$ is $\\beta$-smooth for some parameter $\\beta>0$, the maximal step-size to guarantee convergence is $\\gamma < \\frac{2}{\\beta}$.\n",
        "\n",
        "Below are the tasks that you need to solve. Keep this in mind:\n",
        "- The suggested exercises in the exercise compendium found on the Canvas course page, up until and including the chapter \"Proximal gradient method - basics\", is relevant for this assignment.\n",
        "- Carefully motivate every step in your calculations.\n",
        "- Use __figures__ and __tables__ to motivate your answers.\n",
        "- Figures must have appropriately labeled axes and must be referenced in the main text.\n",
        "- Your code should be written in a quite general manner, i.e., if a question is slightly modified, it should only require slight modifications in your code as well.\n",
        "- Comment your code well.\n",
        "- Make sure you plot in such a way that small quantities (e.g., $\\norm{x^{k+1} - x^k}_{2}$) are visible. In particular, use log-linear plots, where the quantity that should go to $0$ is on the $y$-axis using logarithmic scale, and the iteration number $k$ on the $x$-axis using linear scale.\n",
        "- What you need to submit to Canvas:\n",
        "    - This jupyter notebook containing your solutions.\n",
        "    - An exported pdf version of the jupyter notebook. (One way to do this is to print the notebook in your web browser, and then save as pdf.)\n",
        "\n",
        "This table shows which lectures are needed in order to solve task 1-7:\n",
        "    \n",
        "| Task | Lectures |\n",
        "| ---- | -------- |\n",
        "| 1    | 2, 3     |\n",
        "| 2    | 4        |\n",
        "| 3    | 3, 4     |\n",
        "| 4    | 2, 4     |\n",
        "| 5    | 3, 4     |\n",
        "| 6    | 5        |\n",
        "| 7    | 4        |\n",
        "\n",
        "Task 8-10 can be solved after you have solved task 1-7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqRP6F89v1zr"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 1:\n",
        "\n",
        "Show that $f$ and $\\iota_{S}$ in (2) are convex and show that constraint qualification (CQ) holds. You are allowed to assume that $\\relint S \\neq \\emptyset$. Note that $f$ and $\\iota_{S}$ also are closed, but you do not need to prove this.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "For the composite form $\\min_x f(x) + g(x)$ with $g = \\iota_S$, a common CQ is\n",
        "\n",
        "$$\n",
        "\\operatorname{ri}(\\operatorname{dom} f) \\cap \\operatorname{ri}(\\operatorname{dom} g) \\neq \\emptyset.\n",
        "$$\n",
        "\n",
        "Here $\\operatorname{dom} f = \\mathbb{R}^n \\Rightarrow \\operatorname{ri}(\\operatorname{dom} f) = \\mathbb{R}^n$, and $\\operatorname{dom} g = S \\Rightarrow \\operatorname{ri}(\\operatorname{dom} g) = \\operatorname{ri}(S)$. By assumption $\\operatorname{ri}(S) \\neq \\emptyset$, so the intersection is nonempty. Hence the Fenchel–Rockafellar CQ holds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F0t29kav1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 2:\n",
        "\n",
        "Compute the conjugate functions $f^\\ast$ and $\\iota_{S}^\\ast$. The final expressions are not allowed to be given implicitly via optimization problems. E.g., projection formulas must be solved explicitly.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "Conjugate of $f(x) = \\frac{1}{2} x^\\top Q x + q^\\top x$ with $Q \\in \\mathbb{S}_{++}^n$\n",
        "\n",
        "$$\n",
        "f^*(y) = \\sup_x \\left\\{ y^\\top x - \\frac{1}{2} x^\\top Q x - q^\\top x \\right\\}\n",
        "= \\sup_x \\left\\{ (y - q)^\\top x - \\frac{1}{2} x^\\top Q x \\right\\} \\\\\n",
        "= \\frac{1}{2}(y - q)^\\top Q^{-1}(y - q)\n",
        "= \\frac{1}{2} \\left\\| Q^{-1/2}(y - q) \\right\\|_2^2,\n",
        "\\quad \\text{for all } y \\in \\mathbb{R}^n.\n",
        "$$\n",
        "\n",
        "\n",
        "Conjugate of the indicator $\\iota_S$ for the box\n",
        "$S = \\{ x : a \\leq x \\leq b \\}$\n",
        "\n",
        "The conjugate is the support function $\\sigma_S(y) = \\sup_{x \\in S} y^\\top x$.\n",
        "\n",
        "Since $S = \\prod_{i=1}^n [a_i, b_i]$ is separable,\n",
        "$$\n",
        "\\iota_S^*(y) = \\sigma_S(y) = \\sum_{i=1}^n \\sup_{x_i \\in [a_i, b_i]} y_i x_i\n",
        "= \\sum_{i=1}^n \\max \\{ a_i y_i, b_i y_i \\}.\n",
        "$$\n",
        "\n",
        "One equivalent explicit form is Piecewise (sign) form:\n",
        "\n",
        "  \n",
        "  $$\n",
        "  \\iota_S^*(y) = \\sum_{i=1}^n\n",
        "  \\begin{cases}\n",
        "    b_i y_i, & y_i \\geq 0, \\\\\n",
        "    a_i y_i, & y_i < 0,\n",
        "  \\end{cases}\n",
        "  $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewqTfkaDv1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 3:\n",
        "\n",
        "Write down a Fenchel dual problem to (2). Show that constraint qualification for the dual problem (CQ-D) holds.\n",
        "\n",
        "_Attention/hint:_ Keep track of your minus signs.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "Using the Fenchel template\n",
        "$$\n",
        "\\min_x f(x) + g(x) \\Longleftrightarrow \\max_y \\left( -f^*(-y) - g^*(y) \\right),\n",
        "$$\n",
        "with $g = \\iota_S$, which needs the explicit conjugates:\n",
        "\n",
        "$f^*(y) = \\frac{1}{2}(y - q)^\\top Q^{-1}(y - q)$ (since $Q \\succ 0$).\n",
        "\n",
        "$\n",
        "\\iota_S^*(y) = \\sigma_S(y) = \\sum_{i=1}^n \\max\\{a_i y_i, b_i y_i\\}.\n",
        "$\n",
        "\n",
        "Therefore the dual problem is\n",
        "$$\n",
        "\\max_{y \\in \\mathbb{R}^n} -\\frac{1}{2}(y + q)^\\top Q^{-1}(y + q) - \\sum_{i=1}^n \\max\\{a_i y_i, b_i y_i\\}.\n",
        "$$\n",
        "\n",
        "A convenient case-free expression for the support term is\n",
        "$$\n",
        "\\sum_{i=1}^n \\max\\{a_i y_i, b_i y_i\\} = \\sum_{i=1}^n \\left( \\frac{a_i + b_i}{2} y_i + \\frac{b_i - a_i}{2} |y_i| \\right).\n",
        "$$\n",
        "\n",
        "A standard Fenchel–Rockafellar CQ on the dual pair is\n",
        "$$\n",
        "\\operatorname{ri}(\\operatorname{dom} f^*) \\cap \\left( -\\operatorname{ri}(\\operatorname{dom} \\iota_S^*) \\right) \\neq \\emptyset.\n",
        "$$\n",
        "\n",
        "Here,\n",
        "\n",
        "$\\operatorname{dom} f^* = \\mathbb{R}^n$ , hence $\\operatorname{ri}(\\operatorname{dom} f^*) = \\mathbb{R}^n$.\n",
        "\n",
        "$\\operatorname{dom} \\iota_S^* = \\mathbb{R}^n$, hence $\\operatorname{ri}(\\operatorname{dom} \\iota_S^*) = \\mathbb{R}^n$.\n",
        "\n",
        "Thus $\\mathbb{R}^n \\cap (-\\mathbb{R}^n) = \\mathbb{R}^n \\neq \\emptyset$, so CQ-D holds.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-8H8AuNv1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 4:\n",
        "\n",
        "Show that $f$ and $f^*$ are $\\beta$-, and $\\beta^*$-smooth, respectively. Find expressions for the smallest such parameters $\\beta$ and $\\beta^*$. For instance, show that for any $\\beta' < \\beta$ we have that $f$ is not $\\beta'$-smooth.\n",
        "\n",
        "_Hint:_ Later when calculating the smoothness parameters in Pyhton, make sure to read the documentation carefully so that you use the correct function.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "A function $h$ is $\\beta$-smooth iff $\\nabla h$ is $\\beta$-Lipschitz:\n",
        "\n",
        "$$\n",
        "\\|\\nabla h(u) - \\nabla h(v)\\| \\leq \\beta \\|u - v\\| \\quad \\forall u, v,\n",
        "$$\n",
        "\n",
        "equivalently $\\|\\nabla^2 h(x)\\|_2 \\leq \\beta$ for all $x$.\n",
        "\n",
        "$\n",
        "f(x) = \\frac{1}{2} x^\\top Q x + q^\\top x, \\nabla f(x) = Qx + q$, $\\nabla^2 f(x) = Q$ (constant).\n",
        "\n",
        "Since $Q \\in \\mathbb{S}_{++}^n$ is symmetric, $\\|\\nabla^2 f(x)\\|_2 = \\|Q\\|_2 = \\lambda_{\\max}(Q)$ for all $x$.\n",
        "\n",
        "\n",
        "Therefore:\n",
        "$$\n",
        "\\beta = \\lambda_{\\max}(Q)\n",
        "$$\n",
        "is a smoothness constant for $f$, and it is the smallest one.\n",
        "\n",
        "Pick a unit eigenvector $v$ of $Q$ with eigenvalue $\\lambda_{\\max}(Q)$. For any $t \\neq 0$:\n",
        "$$\n",
        "\\frac{\\|\\nabla f(tv) - \\nabla f(0)\\|}{|tv - 0|} = \\frac{\\|Q(tv)\\|}{|t|} = \\|Qv\\| = \\lambda_{\\max}(Q).\n",
        "$$\n",
        "The Lipschitz ratio equals $\\lambda_{\\max}(Q)$, so any $\\beta' < \\lambda_{\\max}(Q)$ violates the inequality. Hence $\\beta = \\lambda_{\\max}(Q)$ is the smallest possible.\n",
        "\n",
        "$$\n",
        "f^*(y) = \\frac{1}{2}(y - q)^\\top Q^{-1}(y - q)\n",
        "$$\n",
        "\n",
        "$\\nabla f^*(y) = Q^{-1}(y - q)$, $\\nabla^2 f^*(y) = Q^{-1}$ (constant).\n",
        "\n",
        "$\\|Q^{-1}\\|_2 = \\lambda_{\\max}(Q^{-1}) = \\frac{1}{\\lambda_{\\min}(Q)}$.\n",
        "\n",
        "\n",
        "Therefore,\n",
        "$$\n",
        "\\beta^* = \\lambda_{\\max}(Q^{-1}) = \\frac{1}{\\lambda_{\\min}(Q)}\n",
        "$$\n",
        "is a smoothness constant for $f^*$, and it is the smallest one}.\n",
        "\n",
        "Let $w$ be a unit eigenvector of $Q$ with eigenvalue $\\lambda_{\\min}(Q)$. Then $w$ is an eigenvector of $Q^{-1}$ with eigenvalue $1/\\lambda_{\\min}(Q)$. For any $t \\neq 0$,\n",
        "\n",
        "$$\n",
        "\\frac{\\|\\nabla f^*(tw) - \\nabla f^*(0)\\|}{\\|tw - 0\\|} = \\frac{\\|Q^{-1}(tw)\\|}{|t|} = \\|Q^{-1} w\\| = \\frac{1}{\\lambda_{\\min}(Q)}.\n",
        "$$\n",
        "\n",
        "Thus any $\\beta^{*'} < 1/\\lambda_{\\min}(Q)$ fails.\n",
        "\n",
        "Summary:\n",
        "\n",
        "$$\n",
        "\\text{Smallest smoothness of } f : \\quad \\beta = \\lambda_{\\max}(Q). \\\\[6pt]\n",
        "\\text{Smallest smoothness of } f^* : \\quad \\beta^* = \\lambda_{\\max}(Q^{-1}) = \\frac{1}{\\lambda_{\\min}(Q)}. \\\\\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEwu9b8av1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "$\\DeclareMathOperator*{\\argmin}{argmin}$\n",
        "\n",
        "---\n",
        "### Task 5:\n",
        "\n",
        "Compute $\\nabla f$, $\\nabla f^\\ast$, $\\prox_{\\gamma\\iota_{S}}$ and $\\prox_{\\gamma\\iota_{S}^\\ast}$. The final expressions are not allowed to be given implicitly via optimization problems. E.g., projection formulas must be solved explicitly.\n",
        "\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "$f(x) = \\frac{1}{2} x^\\top Q x + q^\\top x$ with $Q \\in \\mathbb{S}_{++}^n$:\n",
        "$$\n",
        "    \\nabla f(x) = Qx + q\n",
        "$$\n",
        "\n",
        "$f^*(y) = \\frac{1}{2} (y - q)^\\top Q^{-1} (y - q)$:\n",
        "$$\n",
        "\\nabla f^*(y) = Q^{-1}(y - q)\n",
        "$$\n",
        "\n",
        "\n",
        "For the box $S = \\{x : a \\leq x \\leq b\\}$, the prox of the indicator is the Euclidean projection onto $S$, it does not depend on $\\gamma$:\n",
        "\n",
        "$$\n",
        "\\left[ \\operatorname{prox}_{\\gamma \\, \\iota_S}(y) \\right]_i = \\min\\{\\max\\{y_i, a_i\\}, b_i\\} \\quad \\text{for } i = 1, \\ldots, n.\n",
        "$$\n",
        "\n",
        "\n",
        "Use Moreau's identity $\\operatorname{prox}_{\\gamma g^*}(y) = y - \\gamma \\, \\operatorname{prox}_{g/\\gamma}(y/\\gamma)$ with $g = \\iota_S$. Since $\\operatorname{prox}_{\\iota_S} = \\Pi_S$ (projection), we get\n",
        "\n",
        "$$\n",
        "\\operatorname{prox}_{\\gamma \\, \\iota_S^*}(y) = y - \\gamma \\, \\Pi_S\\left( \\frac{y}{\\gamma} \\right) = y - \\Pi_{[\\gamma a, \\gamma b]}(y),\n",
        "$$\n",
        "\n",
        "which is :\n",
        "\n",
        "$$\n",
        "\\left[ \\operatorname{prox}_{\\gamma \\, \\iota_S^*}(y) \\right]_i =\n",
        "\\begin{cases}\n",
        "y_i - \\gamma a_i, & y_i < \\gamma a_i, \\\\\n",
        "0, & \\gamma a_i \\leq y_i \\leq \\gamma b_i, \\\\\n",
        "y_i - \\gamma b_i, & y_i > \\gamma b_i.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Equivalently,\n",
        "\n",
        "$$\n",
        "\\left[ \\operatorname{prox}_{\\gamma \\, \\iota_S^*}(y) \\right]_i = y_i - \\min\\{\\max\\{y_i, \\gamma a_i\\}, \\gamma b_i\\}.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC37XKe_v1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 6:\n",
        "\n",
        "Based on your results above, write explicitly out the proximal gradient update rule (4) for both the primal and the dual problem. Use $x$ as the primal variable and $\\mu$ as the dual variable.\n",
        "\n",
        "_Attention/hint:_ Keep track of your minus signs.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "Primal PG update $\\min_x f(x) + \\iota_S(x)$\n",
        "\n",
        "$\\nabla f(x) = Qx + q$\n",
        "$\\operatorname{prox}_{\\gamma \\iota_S}(y) = \\Pi_S(y) = \\left[ \\min\\{\\max\\{y_i, a_i\\}, b_i\\} \\right]_i$\n",
        "\n",
        "\n",
        "So,\n",
        "$$\n",
        "x^{k+1} = \\Pi_S\\left(x^k - \\gamma (Q x^k + q)\\right)\n",
        "$$\n",
        "\n",
        "componentwise:\n",
        "$$\n",
        "x_i^{k+1} = \\min\\left\\{ \\max\\left\\{ x_i^k - \\gamma \\left( (Qx^k)_i + q_i \\right), a_i \\right\\}, b_i \\right\\}, \\quad i = 1, \\ldots, n.\n",
        "$$\n",
        "\n",
        "Valid with any $0 < \\gamma < \\frac{2}{\\lambda_{\\max}(Q)}$.\n",
        "\n",
        "\n",
        "\n",
        "From the Fenchel dual we take the equivalent minimization:\n",
        "$$\n",
        "\\min_\\mu F(\\mu) + G(\\mu), \\quad F(\\mu) = \\frac{1}{2}(\\mu + q)^\\top Q^{-1}(\\mu + q), \\quad G(\\mu) = \\sigma_S(\\mu) = \\iota_S^*(\\mu).\n",
        "$$\n",
        "\n",
        "$\\nabla F(\\mu) = Q^{-1}(\\mu + q)$.\n",
        "$\\operatorname{prox}_{\\eta G}(y) = \\operatorname{prox}_{\\eta \\, \\iota_S^*}(y) = y - \\Pi_{[\\eta a, \\eta b]}(y)$\n",
        "\\\\\n",
        "\n",
        "\n",
        "Thus the dual PG step is\n",
        "\n",
        "$$\n",
        "\\mu^{k+1} = \\operatorname{prox}_{\\eta \\, \\iota_S^*} \\left( \\mu^k - \\eta \\, Q^{-1}(\\mu^k + q) \\right)\n",
        "= \\left( \\mu^k - \\eta \\, Q^{-1}(\\mu^k + q) \\right) - \\Pi_{[\\eta a, \\eta b]} \\left( \\mu^k - \\eta \\, Q^{-1}(\\mu^k + q) \\right).\n",
        "$$\n",
        "\n",
        "Equivalently, componentwise with $y_i^k := \\mu_i^k - \\eta \\left[Q^{-1}(\\mu^k + q)\\right]_i$,\n",
        "$$\n",
        "\\mu_i^{k+1} =\n",
        "\\begin{cases}\n",
        "y_i^k - \\eta a_i, & y_i^k < \\eta a_i, \\\\\n",
        "0, & \\eta a_i \\leq y_i^k \\leq \\eta b_i, \\\\\n",
        "y_i^k - \\eta b_i, & y_i^k > \\eta b_i,\n",
        "\\end{cases}\n",
        "\\quad i = 1, \\ldots, n.\n",
        "$$\n",
        "\n",
        "Valid with any $0 < \\eta < \\frac{2}{\\beta^*} = \\frac{2}{\\lambda_{\\max}(Q^{-1})} = 2 \\lambda_{\\min}(Q)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaBnhUwHv1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 7:\n",
        "\n",
        "Suppose that $\\mu^\\star\\in\\R^{n}$ is an optimal solution to the dual problem you found in Task 3. Given $\\mu^\\star$, and __starting from the optimality condition for the dual problem (given by _Fermat's rule_)__, recover an optimal point $x^{\\star}\\in\\R^{n}$ to the primal problem (2), and show that this $x^{\\star}$ is in fact an optimal solution to the primal problem (2). Motivate each step in your argument carefully.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "From Task 3 the dual (concave maximization) is\n",
        "$$\n",
        "\\max_{\\mu \\in \\mathbb{R}^n} D(\\mu) := -f^*(-\\mu) - \\iota_S^*(\\mu) = -\\frac{1}{2}(\\mu + q)^\\top Q^{-1}(\\mu + q) - \\sigma_S(\\mu),\n",
        "$$\n",
        "where $\\sigma_S = \\iota_S^*$ is the support function of the box $S$.\n",
        "\n",
        "For a concave maximization, Fermat's rule says\n",
        "$$\n",
        "0 \\in \\partial(-D)(\\mu^\\star).\n",
        "$$\n",
        "\n",
        "Compute $\\partial(-D)$:\n",
        "$$\n",
        "-D(\\mu) = f^*(-\\mu) + \\sigma_S(\\mu), \\qquad \\nabla f^*(y) = Q^{-1}(y - q).\n",
        "$$\n",
        "\n",
        "By the chain rule,\n",
        "$$\n",
        "\\nabla_\\mu f^*(-\\mu) = -\\nabla f^*(-\\mu) = -Q^{-1}(-\\mu - q) = Q^{-1}(\\mu + q).\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "$$\n",
        "0 \\in Q^{-1}(\\mu^\\star + q) + \\partial \\sigma_S(\\mu^\\star).\n",
        "$$\n",
        "\n",
        "Define\n",
        "$$\n",
        "x^\\star := -Q^{-1}(\\mu^\\star + q) = \\nabla f^*(-\\mu^\\star).\n",
        "$$\n",
        "\n",
        "Then\n",
        "$$\n",
        "-Q^{-1}(\\mu^\\star + q) \\in \\partial \\sigma_S(\\mu^\\star)\n",
        "\\quad \\Longleftrightarrow \\quad\n",
        "x^\\star \\in \\partial \\sigma_S(\\mu^\\star).\n",
        "$$\n",
        "\n",
        "By the conjugacy/subgradient symmetry,\n",
        "$$\n",
        "x \\in \\partial g^*(\\mu) \\Longleftrightarrow \\mu \\in \\partial g(x),\n",
        "$$\n",
        "so with $g = \\iota_S$ and $g^* = \\sigma_S$, gives\n",
        "$$\n",
        "\\mu^\\star \\in \\partial \\iota_S(x^\\star) = N_S(x^\\star)\n",
        "$$\n",
        "\n",
        "Consequences:\n",
        "\n",
        "$N_S(x^\\star) \\neq \\emptyset$ implies $x^\\star \\in S$ (primal feasibility).\n",
        "\n",
        "Coordinatewise normal-cone conditions (complementarity):\n",
        "$$\n",
        "\\left\\{\n",
        "\\begin{aligned}\n",
        "a_i < x_i^\\star < b_i &\\Rightarrow \\mu_i^\\star = 0, \\\\\n",
        "x_i^\\star = a_i &\\Rightarrow \\mu_i^\\star \\leq 0, \\\\\n",
        "x_i^\\star = b_i &\\Rightarrow \\mu_i^\\star \\geq 0.\n",
        "\\end{aligned}\n",
        "\\right.\n",
        "$$\n",
        "\n",
        "Compute the primal gradient at $x^\\star$:\n",
        "$$\n",
        "\\nabla f(x^\\star) = Qx^\\star + q = Q\\left(-Q^{-1}(\\mu^\\star + q)\\right) + q = -(\\mu^\\star + q) + q = -\\mu^\\star.\n",
        "$$\n",
        "\n",
        "Combine:\n",
        "$$\n",
        "0 \\in \\nabla f(x^\\star) + \\partial \\iota_S(x^\\star) = (-\\mu^\\star) + \\partial \\iota_S(x^\\star).\n",
        "$$\n",
        "\n",
        "Since $\\mu^\\star \\in \\partial \\iota_S(x^\\star)$, the right-hand side contains $0$. This is exactly Fermat's rule for the primal problem\n",
        "$$\n",
        "\\min_x f(x) + \\iota_S(x).\n",
        "$$\n",
        "\n",
        "Hence $x^\\star$ is optimal for the primal.  \n",
        "Because $Q \\succ 0$ makes $f$ strongly convex and $\\iota_S$ is convex, the primal minimizer is unique; thus this $x^\\star$ is the primal solution.\n",
        "\n",
        "Given an optimal dual $\\mu^\\star$,\n",
        "$$\n",
        "x^\\star = -Q^{-1}(\\mu^\\star + q) \\quad \\text{and} \\quad \\mu^\\star \\in N_S(x^\\star) \\; \\text{(so } x^\\star \\in S\\text{)}.\n",
        "$$\n",
        "\n",
        "Then $0 \\in \\nabla f(x^\\star) + \\partial \\iota_S(x^\\star)$, proving primal optimality.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG-ZLlR2v1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 8:\n",
        "\n",
        "Use your results above to fill in the functions below.\n",
        "\n",
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUFeTpf1v1zs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def quad(x,Q,q):\n",
        "    \"\"\"\n",
        "    quad(x,Q,q) computes the quadratic function (1/2)x'Qx + q'x\n",
        "\n",
        "    :param x: the variable of the quadratic function\n",
        "    :param Q: the matrix in the quadratic function that corresponds to the quadratic form\n",
        "    :param q: the vector in the quadratic function that corresponds to the linear part\n",
        "    :return: (1/2)x'Qx + q'x\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def quadconj(mu,Q,q):\n",
        "    \"\"\"\n",
        "    quadconj(mu,Q,q) computes the conjugate function of the\n",
        "    quadratic function (1/2)x'Qx + q'x, evaluated at mu\n",
        "\n",
        "    :param mu: the variable of the conjugate function\n",
        "    :param Q: the matrix in the quadratic function that corresponds to the quadratic form\n",
        "    :param q: the vector in the quadratic function that corresponds to the linear part\n",
        "    :return: conjugate of (1/2)x'Qx + q'x, evaluated at mu\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def box(x,a,b):\n",
        "    \"\"\"\n",
        "    box(x,a,b) computes the indicator function of the box contraint\n",
        "    [a,b]\n",
        "\n",
        "    :param x: the variable of the indicator function\n",
        "    :param a: the left vector defining the box contraint\n",
        "    :param b: the right vector defining the box contraint\n",
        "    :return: 0 if x is in [a,b] and infinity otherwise\n",
        "    \"\"\"\n",
        "    if np.all(a <= x) and np.all(x <= b):\n",
        "        return 0\n",
        "    else:\n",
        "        return np.Inf\n",
        "\n",
        "def boxconj(mu,a,b):\n",
        "    \"\"\"\n",
        "    boxconj(mu,a,b) computes the conjugate function of the indicator function\n",
        "    of the box contraint [a,b], evaluated at mu\n",
        "\n",
        "    :param mu: the variable of the conjugate function\n",
        "    :param a: the left vector defining the box contraint\n",
        "    :param b: the right vector defining the box contraint\n",
        "    :return: conjugate of the indicator function of the box contraint [a,b], evaluated at mu\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def grad_quad(x,Q,q):\n",
        "    \"\"\"\n",
        "    grad_quad(x,Q,q) computes the gradient of the quadratic function (1/2)x'Qx + q'x\n",
        "\n",
        "    :param x: the variable of the quadratic function\n",
        "    :param Q: the matrix in the quadratic function that corresponds to the quadratic form\n",
        "    :param q: the vector in the quadratic function that corresponds to the linear part\n",
        "    :return: gradient of (1/2)x'Qx + q'x\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def grad_quadconj(mu,Q,q):\n",
        "    \"\"\"\n",
        "    grad_quadconj(mu,Q,q) computes the gradient of the conjugate function of the\n",
        "    the quadratic function (1/2)x'Qx + q'x, evaluated at mu\n",
        "\n",
        "    :param mu: the variable of the conjugate function\n",
        "    :param Q: the matrix in the quadratic function that corresponds to the quadratic form\n",
        "    :param q: the vector in the quadratic function that corresponds to the linear part\n",
        "    :return: gradient of the conjugate of (1/2)x'Qx + q'x, evaluated at mu\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def prox_box(x,a,b,gamma):\n",
        "    \"\"\"\n",
        "    prox_box(x,a,b,gamma) computes proximal operator of the indicator function\n",
        "    of the box contraint [a,b], evaluated at x\n",
        "\n",
        "    :param x: the variable of the poximal operator\n",
        "    :param a: the left vector defining the box contraint\n",
        "    :param b: the right vector defining the box contraint\n",
        "    :param gamma: the step-size parameter\n",
        "    :return: proximal operator of the indicator function of the\n",
        "    box contraint [a,b], evaluated at x\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def prox_boxconj(mu,a,b,gamma):\n",
        "    \"\"\"\n",
        "    prox_box(mu,a,b,gamma) computes proximal operator of the conjugate function of\n",
        "    the indicator function of the box contraint [a,b], evaluated at mu\n",
        "\n",
        "    :param mu: the variable of the poximal operator\n",
        "    :param a: the left vector defining the box contraint\n",
        "    :param b: the right vector defining the box contraint\n",
        "    :param gamma: the step-size parameter\n",
        "    :return: proximal operator of the conjugate function of the indicator function of the\n",
        "    box contraint [a,b], evaluated at mu\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ...\n",
        "\n",
        "def dual_to_primal(mu,Q,q,a,b):\n",
        "    \"\"\"\n",
        "    dual_to_primal(mu,Q,q,a,b) computes the solution x* to the primal problem\n",
        "    given a solution mu* to the dual problem.\n",
        "\n",
        "    :param mu: the dual variable\n",
        "    :param Q: the matrix in the quadratic function that corresponds to the quadratic form\n",
        "    :param q: the vector in the quadratic function that corresponds to the linear part\n",
        "    :param a: the left vector defining the box contraint\n",
        "    :param b: the right vector defining the box contraint\n",
        "    :return: the extracted primal variable\n",
        "    \"\"\"\n",
        "    # Write your solution here\n",
        "    return ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSbUoMtCv1zs"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 9:\n",
        "\n",
        "Below is a function for generating $Q$, $q$, $a$, and $b$ that define the quadratic function $f$ and the box constraint set $S$. Use Task 8 to solve the primal problem using the proximal gradient method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrofzhpPv1zs"
      },
      "outputs": [],
      "source": [
        "def problem_data():\n",
        "    \"\"\"\n",
        "    problem_data() generates the problem data variables Q, q, a and b\n",
        "\n",
        "    :return: (Q,q,a,b)\n",
        "    \"\"\"\n",
        "    rs = np.random.RandomState(np.random.MT19937(np.random.SeedSequence(1)))\n",
        "    n = 20\n",
        "    Q = rs.randn(n,n)\n",
        "    Q = Q.T@Q\n",
        "    q = rs.randn(n)\n",
        "    a = -rs.rand(n)\n",
        "    b = rs.rand(n)\n",
        "    return Q, q, a, b\n",
        "\n",
        "(Q,q,a,b) = problem_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHrU7CEJv1zt"
      },
      "source": [
        "__a)__ What seems to be the best choice of $\\gamma$?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJknQQEvv1zt"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsakwSvXv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__b)__ Does the upper bound $\\gamma < \\frac{2}{\\beta}$ seem reasonable?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBBFxPRKv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "Test different initial points for the algorithm:\n",
        "\n",
        "__c)__ Does this affect the point the algorithm converges to?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2qgHwSLv1zt"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5upK-daTv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__d)__ Carefully motivate theoretically why/why not it affects the final point. _Hint:_ Look at the objective function in (2).\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_IGBHLQv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__e)__ Does your final point $x^{\\text{final}}$ satisfy the constraint $x^{\\text{final}} \\in S$?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr1wsXgqv1zt"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7BI28Zxv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__f)__ What about the iterates, do they always satisfy the constraint, $x^k \\in S$? Why/why not?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P15r3EPRv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "---\n",
        "### Task 10:\n",
        "\n",
        "Solve the dual problem.\n",
        "\n",
        "__a)__ Similar to the previous task, find/verify the upper bound on the step-size and find a good step-size choice.\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whEtHRnXv1zt"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kju7viAIv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "Let $x^{\\text{final}}$ be the final points from Task 9 and $\\mu^{\\text{final}}$ the final point for the dual problem. Let $\\hat{x}^{\\text{final}}$ final primal points extracted from the final dual point $\\mu^{\\text{final}}$ using the expression from Task 7:\n",
        "\n",
        "__b)__ Are $x^{\\text{final}}$ and $\\hat{x}^{\\text{final}}$ the same?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PypsTxq7v1zt"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdTNmuR0v1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__c)__ Is $\\hat{x}^{\\text{final}}$ in the box $S$?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4hEgjS7v1zt"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXlqynJhv1zt"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__d)__ Let $\\mu^k$ be the iterates of the dual method, using the expression from Task 7, extract the primal iterates $\\hat{x}^k$ from $\\mu^k$. Does $\\hat{x}^k$ always satisfy the constraint $\\hat{x}^k \\in S$?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dr7qyiUv1zu"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBmEsdZzv1zu"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__e)__ How do the function values $f\\left(\\hat{x}^k\\right)$ develop over the iterations?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbCThKe1v1zu"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znvA82pYv1zu"
      },
      "source": [
        "$\\DeclareMathOperator{\\prox}{prox}$\n",
        "$\\newcommand{\\R}{\\mathbb{R}}$\n",
        "$\\newcommand{\\Sym}{\\mathbb{S}}$\n",
        "$\\newcommand{\\norm}[1]{\\lVert{#1}\\rVert}$\n",
        "$\\DeclareMathOperator{\\sign}{sign}$\n",
        "$\\DeclareMathOperator{\\diag}{diag}$\n",
        "$\\DeclareMathOperator{\\relint}{relint}$\n",
        "$\\DeclareMathOperator{\\dom}{dom}$\n",
        "\n",
        "__f)__ What about $f\\left(\\hat{x}^k\\right)+\\iota_{S}\\left(\\hat{x}^k\\right)$?\n",
        "\n",
        "__Solution:__\n",
        "\n",
        "_Fill in your solution here!_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kia1OgN6v1zu"
      },
      "outputs": [],
      "source": [
        "# Write your solution here"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}